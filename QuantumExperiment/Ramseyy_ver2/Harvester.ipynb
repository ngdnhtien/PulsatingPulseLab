{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f96a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# IBM Quantum Experience\n",
    "from qiskit import IBMQ, pulse, schedule\n",
    "from qiskit.circuit import Parameter, QuantumCircuit, Gate\n",
    "from qiskit.tools.monitor import job_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f26889",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q', group='open', project='main')\n",
    "backend = provider.get_backend('ibmq_manila')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ac9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit = 0 \n",
    "scale_factor = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a1da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that are functional\n",
    "\n",
    "def getJobData(job, average):\n",
    "    \"\"\"Retrieve data from a job that has already run.\n",
    "    Args:\n",
    "        job (Job): The job whose data you want.\n",
    "        average (bool): If True, gets the data assuming data is an average.\n",
    "                        If False, gets the data assuming it is for single shots.\n",
    "    Return:\n",
    "        list: List containing job result data.\n",
    "    \"\"\"\n",
    "    job_results = job.result()  # timeout parameter set to 120 s\n",
    "    result_data = []\n",
    "    for i in range(len(job_results.results)):\n",
    "        if average:  # get avg data\n",
    "            result_data.append(np.real(job_results.get_memory(i)[qubit] * scale_factor))\n",
    "        else:  # get single data\n",
    "            result_data.append(job_results.get_memory(i)[:, qubit] * scale_factor)\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def getClosestMultipleSixteen(num):\n",
    "    \"\"\"Compute the nearest multiple of 16. Needed because pulse enabled devices require\n",
    "    durations which are multiples of 16 samples.\n",
    "    \"\"\"\n",
    "    return int(num + 8) - (int(num + 8) % 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "772b682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632741c92240618acc4d6d2d\n"
     ]
    }
   ],
   "source": [
    "job = backend.retrieve_job('632741c92240618acc4d6d2d')\n",
    "print(job.job_id())\n",
    "raw_ramsey_data = getJobData(job, average=False)\n",
    "savetxt('raw_ramsey_noypulse_exp_data_' + job.job_id() + '.csv', raw_ramsey_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "573f2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('raw_ramsey_noypulse_exp_data_' + job.job_id() + '.csv', sep=\",\", header=None)\n",
    "data = data.applymap(lambda s: complex(s.replace('i', 'j'))).values\n",
    "\n",
    "zero_data = data[0]\n",
    "one_data = data[1]\n",
    "two_data = data[2]\n",
    "\n",
    "\n",
    "def reshape_complex_vec(vec):\n",
    "    \"\"\"Take in complex vector vec and return 2d array w/ real, imag entries. This is needed for the learning.\n",
    "    Args:\n",
    "        vec (list): complex vector of data\n",
    "    Returns:\n",
    "        list: vector w/ entries given by (real(vec], imag(vec))\n",
    "    \"\"\"\n",
    "    length = len(vec)\n",
    "    vec_reshaped = np.zeros((length, 2))\n",
    "    for i in range(len(vec)):\n",
    "        vec_reshaped[i] = [np.real(vec[i]), np.imag(vec[i])]\n",
    "    return vec_reshaped\n",
    "\n",
    "\n",
    "# Create IQ vector (split real, imag parts)\n",
    "zero_data_reshaped = reshape_complex_vec(zero_data)\n",
    "one_data_reshaped = reshape_complex_vec(one_data)\n",
    "two_data_reshaped = reshape_complex_vec(two_data)\n",
    "\n",
    "IQ_012_data = np.concatenate((zero_data_reshaped, one_data_reshaped, two_data_reshaped))\n",
    "\n",
    "NUM_SHOTS = 20000\n",
    "\n",
    "# construct vector w/ 0's, 1's and 2's (for testing)\n",
    "state_012 = np.zeros(NUM_SHOTS)  # shots gives number of experiments\n",
    "state_012 = np.concatenate((state_012, np.ones(NUM_SHOTS)))\n",
    "state_012 = np.concatenate((state_012, 2 * np.ones(NUM_SHOTS)))\n",
    "\n",
    "# Shuffle and split data into training and test sets\n",
    "IQ_012_train, IQ_012_test, state_012_train, state_012_test = train_test_split(IQ_012_data, state_012, test_size=0.5)\n",
    "\n",
    "# Set up the LDA\n",
    "LDA_012 = LinearDiscriminantAnalysis()\n",
    "LDA_012.fit(IQ_012_train, state_012_train)\n",
    "\n",
    "\n",
    "def count(job, discriminator):\n",
    "    data = getJobData(job, average=False)\n",
    "    sched_data = []\n",
    "    for i in range(len(data)):\n",
    "        sched_data.append(reshape_complex_vec(data[i]))\n",
    "    discrim_data = []\n",
    "    for j in range(len(sched_data)):\n",
    "        discrim_data.append(discriminator.predict(sched_data[j]))\n",
    "    final_result = []\n",
    "    for k in range(len(discrim_data)):\n",
    "        result = {'0': 0, '1': 0, '2': 0}\n",
    "        for l in range(len(discrim_data[k])):\n",
    "            if discrim_data[k][l] == 0.0:\n",
    "                result['0'] += 1\n",
    "            elif discrim_data[k][l] == 1.0:\n",
    "                result['1'] += 1\n",
    "            elif discrim_data[k][l] == 2.0:\n",
    "                result['2'] += 1\n",
    "            else:\n",
    "                print('Unexpected behavior')\n",
    "        final_result.append(result)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f78b1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "discr_data = count(job, LDA_012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05e7935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsey_exp_data = [[discr_data[i]['0'] / 20000, discr_data[i]['1'] / 20000, discr_data[i]['2'] / 20000] for i in\n",
    "                   range(np.shape(discr_data)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91d3beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('raw_ramsey_data_' + job.job_id() + '.csv', ramsey_exp_data, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
